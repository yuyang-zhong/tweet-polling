{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\CK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# #!pip install geocoder\n",
    "# !pip install gensim\n",
    "import geocoder\n",
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import pprint\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "import nltk\n",
    "from nltk import word_tokenize, tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "#!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178897, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_pd = pd.read_csv('../data/hashtag_donaldtrump.csv', engine='python')\n",
    "trump_df = trump_pd[trump_pd['country'] == 'United States of America']\n",
    "trump_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153595, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_pd = pd.read_csv('../data/hashtag_joebiden.csv', engine='python')\n",
    "biden_df = biden_pd[biden_pd['country'] == 'United States of America']\n",
    "biden_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153595, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biden_pd = pd.read_csv('../data/hashtag_joebiden.csv', engine='python')\n",
    "biden_df = biden_pd[biden_pd['country'] == 'United States of America']\n",
    "biden_df.head(5)\n",
    "biden_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dates(df):    \n",
    "    datetimes = []\n",
    "    for date in df['created_at']:\n",
    "        year = int(date[0:4])\n",
    "        month = int(date[5:7])\n",
    "        day = int(date[8:10])\n",
    "        \n",
    "        datetimes.append(datetime.datetime(year, month, day))\n",
    "    \n",
    "    df['created_datetime'] = datetimes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(116290, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_df = clean_dates(trump_df)\n",
    "trump_df_pre = trump_df[trump_df['created_datetime'] < datetime.datetime(2020, 11, 3)]\n",
    "trump_df_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(89399, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_df = clean_dates(biden_df)\n",
    "biden_df_pre = biden_df[biden_df['created_datetime'] < datetime.datetime(2020, 11, 3)]\n",
    "biden_df_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    pattern = r'''(?x)  # set flag to allow verbose regexps\n",
    "    (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "    |\\w+(?:[-']\\w+)*    # words with optional internal hyphens\n",
    "    |\\$?\\d+(?:\\.\\d+)?   # currency, e.g. $12.80 \n",
    "    |\\.\\.\\.             # elipses\n",
    "    |[.,;\"'?()-_`]      # these are separate tokens\n",
    "    '''\n",
    "    string_tweets = \" \".join(tweets)\n",
    "    tokenized_raw = \" \".join(nltk.regexp_tokenize(string_tweets, pattern))\n",
    "    tokenized_raw = tokenize.sent_tokenize(tokenized_raw)\n",
    "\n",
    "    #normalizing text\n",
    "    # Remove punctuations\n",
    "    nopunct = []\n",
    "    for sent in tokenized_raw:\n",
    "        a = [w for w in sent.split() if w not in string.punctuation]\n",
    "        nopunct.append(\" \".join(a))\n",
    "        \n",
    "    # Word tokenize\n",
    "    tokens = [nltk.word_tokenize(sent) for sent in nopunct]\n",
    "    return(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206094, 70)\n"
     ]
    }
   ],
   "source": [
    "trump_tokens = clean_tweets(trump_df_pre.tweet.tolist())\n",
    "trump_unique_words = list(set([item for sublist in trump_tokens for item in sublist]))\n",
    "trump_model = gensim.models.Word2Vec(trump_tokens, min_count=1, size=70, window=5)\n",
    "trump_vector_list = trump_model[trump_unique_words]\n",
    "print(np.array(trump_vector_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160456, 70)\n"
     ]
    }
   ],
   "source": [
    "biden_tokens = clean_tweets(biden_df_pre.tweet.tolist())\n",
    "biden_unique_words = list(set([item for sublist in biden_tokens for item in sublist]))\n",
    "biden_model = gensim.models.Word2Vec(biden_tokens, min_count=1, size=70, window=5)\n",
    "biden_vector_list = biden_model[biden_unique_words]\n",
    "print(np.array(biden_vector_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "trump_X = np.ones(70)\n",
    "for word in trump_unique_words:\n",
    "    trump_X = np.vstack((trump_X, trump_model[word]))\n",
    "trump_X = trump_X[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "biden_X = np.ones(70)\n",
    "for word in biden_unique_words:\n",
    "    biden_X = np.vstack((biden_X, biden_model[word]))\n",
    "biden_X = biden_X[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_X_df = pd.DataFrame(data=biden_X)\n",
    "biden_X_df['word'] = biden_unique_words\n",
    "biden_X_df.to_csv('biden_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_X_df = pd.DataFrame(data=trump_X)\n",
    "trump_X_df['word'] = trump_unique_words\n",
    "trump_X_df.to_csv('trump_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_biden = KMeans(n_clusters = 2, random_state=0)\n",
    "kmeans_biden.fit(biden_X)\n",
    "biden_X_df['label'] = kmeans_biden.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polarity_scores(df):\n",
    "    tweets = df['tweet']\n",
    "    punct_re = r'[^(\\w)#!?@]'\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    clean_tweets = tweets.str.replace(punct_re, ' ', regex=True).to_list()\n",
    "\n",
    "    polarity_list = []\n",
    "    for tweet in clean_tweets:\n",
    "        vs = analyzer.polarity_scores(tweet)\n",
    "        vs['tweet'] = tweet\n",
    "        polarity_list.append(vs)\n",
    "        \n",
    "    new_df = pd.DataFrame(polarity_list)\n",
    "    new_df['state'] = df['state']\n",
    "    new_df = new_df[['tweet', 'state', 'compound', 'pos', 'neg', 'neu']].sort_values(by=['compound'], ascending=False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_polarity_df = generate_polarity_scores(trump_df_pre)\n",
    "trump_polarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>compound</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69218</td>\n",
       "      <td>TIE SCENARIOS  2016 map but     Biden wins AZ ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82725</td>\n",
       "      <td>#Trump says he loves #Texas  But #Biden loves ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21681</td>\n",
       "      <td>@DrBiden And everything must go!  #joebiden se...</td>\n",
       "      <td>California</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83839</td>\n",
       "      <td>@lindyli Wow!!! Lindy  this is so amazing  awe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17882</td>\n",
       "      <td>@ThatEricAlper I have a friend  @JoeBiden! I t...</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46171</td>\n",
       "      <td>@JoeBiden HA HA HA HA HA!!! ðŸ  ðŸ  ðŸ  ðŸ  ðŸ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8789</td>\n",
       "      <td>@DustinGrowick My daughters!! I m a widowed mo...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58860</td>\n",
       "      <td>A Precious Human life by HH #DalaiLama hangs i...</td>\n",
       "      <td>California</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16822</td>\n",
       "      <td>It s like taking a guess when the only answer ...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6860</td>\n",
       "      <td>@PSU_Blaze Oh but it did  The separate situati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "69218  TIE SCENARIOS  2016 map but     Biden wins AZ ...   \n",
       "82725  #Trump says he loves #Texas  But #Biden loves ...   \n",
       "21681  @DrBiden And everything must go!  #joebiden se...   \n",
       "83839  @lindyli Wow!!! Lindy  this is so amazing  awe...   \n",
       "17882  @ThatEricAlper I have a friend  @JoeBiden! I t...   \n",
       "46171  @JoeBiden HA HA HA HA HA!!! ðŸ  ðŸ  ðŸ  ðŸ  ðŸ...   \n",
       "8789   @DustinGrowick My daughters!! I m a widowed mo...   \n",
       "58860  A Precious Human life by HH #DalaiLama hangs i...   \n",
       "16822  It s like taking a guess when the only answer ...   \n",
       "6860   @PSU_Blaze Oh but it did  The separate situati...   \n",
       "\n",
       "                      state  compound    pos    neg    neu  \n",
       "69218                   NaN    0.9944  0.520  0.000  0.480  \n",
       "82725                   NaN    0.9911  0.605  0.000  0.395  \n",
       "21681            California    0.9901  0.537  0.000  0.463  \n",
       "83839                   NaN    0.9876  0.588  0.000  0.412  \n",
       "17882        South Carolina    0.9873  0.487  0.000  0.513  \n",
       "46171                   NaN    0.9870  0.457  0.068  0.475  \n",
       "8789   District of Columbia    0.9864  0.501  0.044  0.455  \n",
       "58860            California    0.9860  0.387  0.000  0.613  \n",
       "16822  District of Columbia    0.9855  0.475  0.000  0.525  \n",
       "6860                    NaN    0.9847  0.477  0.060  0.463  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_polarity_df = generate_polarity_scores(biden_df_pre)\n",
    "biden_polarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_polarity(df):\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        score = row['pos'] - row['neg']\n",
    "        if score > 0.1:\n",
    "            labels.append(1)\n",
    "        elif score < -0.1:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(-1)\n",
    "    df['label'] = labels\n",
    "    df.sort_values(by = 'label')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>compound</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69218</td>\n",
       "      <td>TIE SCENARIOS  2016 map but     Biden wins AZ ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82725</td>\n",
       "      <td>#Trump says he loves #Texas  But #Biden loves ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21681</td>\n",
       "      <td>@DrBiden And everything must go!  #joebiden se...</td>\n",
       "      <td>California</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83839</td>\n",
       "      <td>@lindyli Wow!!! Lindy  this is so amazing  awe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17882</td>\n",
       "      <td>@ThatEricAlper I have a friend  @JoeBiden! I t...</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46171</td>\n",
       "      <td>@JoeBiden HA HA HA HA HA!!! ðŸ  ðŸ  ðŸ  ðŸ  ðŸ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8789</td>\n",
       "      <td>@DustinGrowick My daughters!! I m a widowed mo...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58860</td>\n",
       "      <td>A Precious Human life by HH #DalaiLama hangs i...</td>\n",
       "      <td>California</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16822</td>\n",
       "      <td>It s like taking a guess when the only answer ...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6860</td>\n",
       "      <td>@PSU_Blaze Oh but it did  The separate situati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "69218  TIE SCENARIOS  2016 map but     Biden wins AZ ...   \n",
       "82725  #Trump says he loves #Texas  But #Biden loves ...   \n",
       "21681  @DrBiden And everything must go!  #joebiden se...   \n",
       "83839  @lindyli Wow!!! Lindy  this is so amazing  awe...   \n",
       "17882  @ThatEricAlper I have a friend  @JoeBiden! I t...   \n",
       "46171  @JoeBiden HA HA HA HA HA!!! ðŸ  ðŸ  ðŸ  ðŸ  ðŸ...   \n",
       "8789   @DustinGrowick My daughters!! I m a widowed mo...   \n",
       "58860  A Precious Human life by HH #DalaiLama hangs i...   \n",
       "16822  It s like taking a guess when the only answer ...   \n",
       "6860   @PSU_Blaze Oh but it did  The separate situati...   \n",
       "\n",
       "                      state  compound    pos    neg    neu  label  \n",
       "69218                   NaN    0.9944  0.520  0.000  0.480      1  \n",
       "82725                   NaN    0.9911  0.605  0.000  0.395      1  \n",
       "21681            California    0.9901  0.537  0.000  0.463      1  \n",
       "83839                   NaN    0.9876  0.588  0.000  0.412      1  \n",
       "17882        South Carolina    0.9873  0.487  0.000  0.513      1  \n",
       "46171                   NaN    0.9870  0.457  0.068  0.475      1  \n",
       "8789   District of Columbia    0.9864  0.501  0.044  0.455      1  \n",
       "58860            California    0.9860  0.387  0.000  0.613      1  \n",
       "16822  District of Columbia    0.9855  0.475  0.000  0.525      1  \n",
       "6860                    NaN    0.9847  0.477  0.060  0.463      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_polarity_df = label_polarity(biden_polarity_df)\n",
    "biden_polarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_polarity_df = label_polarity(trump_polarity_df)\n",
    "trump_polarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_hashtags(df, top_hashtag_num):\n",
    "    pos_df = df[df['label'] == 1]\n",
    "    pos_hashtag = []\n",
    "    for tweet in pos_df['tweet']:\n",
    "        pos_hashtag.extend(re.findall(r\"(?!#trump|#biden|#Trump|#Biden|#DonaldTrump|#JoeBiden|#joebiden)#(\\w+)\", tweet))\n",
    "        \n",
    "    neg_df = df[df['label'] == 0]\n",
    "    neg_hashtag = []\n",
    "    for tweet in neg_df['tweet']:\n",
    "        neg_hashtag.extend(re.findall(r\"(?!#trump|#biden|#Trump|#Biden|#DonaldTrump|#JoeBiden|#joebiden)#(\\w+)\", tweet))\n",
    "        \n",
    "    neu_df = df[df['label'] == -1]\n",
    "    neu_hashtag = []\n",
    "    for tweet in neu_df['tweet']:\n",
    "        neu_hashtag.extend(re.findall(r\"(?!#trump|#biden|#Trump|#Biden|#DonaldTrump|#JoeBiden|#joebiden)#(\\w+)\", tweet))\n",
    "    \n",
    "    hashtags = []\n",
    "    hashtags.append(Counter(pos_hashtag).most_common(top_hashtag_num))\n",
    "    hashtags.append(Counter(neg_hashtag).most_common(top_hashtag_num))\n",
    "    hashtags.append(Counter(neu_hashtag).most_common(top_hashtag_num))\n",
    "    \n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_hashtags = find_most_hashtags(trump_polarity_df, 5)\n",
    "biden_hashtags = find_most_hashtags(biden_polarity_df, 5)\n",
    "print(trump_hashtags)\n",
    "print(biden_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what kind of groups would clustering sort them into\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
