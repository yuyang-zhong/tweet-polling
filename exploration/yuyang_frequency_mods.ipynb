{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/combined_labeled_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>One of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>#Trump #PresidentTrump #Trump2020LandslideVict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06  #Trump: As a student I used to hear for years,...   \n",
       "1  4.741380e+07  You get a tie! And you get a tie! #Trump ‘s ra...   \n",
       "2  1.138416e+09  @CLady62 Her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  One of the single most effective remedies to e...   \n",
       "4  1.243315e+18  #Trump #PresidentTrump #Trump2020LandslideVict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  \n",
       "0                Oregon    2.0            1.0      0.461917     -1  \n",
       "1  District of Columbia    4.0            3.0      0.000000      0  \n",
       "2            California    2.0            0.0     -0.323204      1  \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1  \n",
       "4            California    3.0            5.0      0.513350     -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>#trump: as a student i used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>you get a tie! and you get a tie! #trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@clady62 her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>#trump #presidenttrump #trump2020landslidevict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06  #trump: as a student i used to hear for years,...   \n",
       "1  4.741380e+07  you get a tie! and you get a tie! #trump ‘s ra...   \n",
       "2  1.138416e+09  @clady62 her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  one of the single most effective remedies to e...   \n",
       "4  1.243315e+18  #trump #presidenttrump #trump2020landslidevict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  \n",
       "0                Oregon    2.0            1.0      0.461917     -1  \n",
       "1  District of Columbia    4.0            3.0      0.000000      0  \n",
       "2            California    2.0            0.0     -0.323204      1  \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1  \n",
       "4            California    3.0            5.0      0.513350     -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: str(x).lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>trump: as a student i used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>you get a tie! and you get a tie!  trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@clady62 her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>trump  presidenttrump  trump2020landslidevict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06   trump: as a student i used to hear for years,...   \n",
       "1  4.741380e+07  you get a tie! and you get a tie!  trump ‘s ra...   \n",
       "2  1.138416e+09  @clady62 her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  one of the single most effective remedies to e...   \n",
       "4  1.243315e+18   trump  presidenttrump  trump2020landslidevict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  \n",
       "0                Oregon    2.0            1.0      0.461917     -1  \n",
       "1  District of Columbia    4.0            3.0      0.000000      0  \n",
       "2            California    2.0            0.0     -0.323204      1  \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1  \n",
       "4            California    3.0            5.0      0.513350     -1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('#', ' ', x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(tweet, word): \n",
    "    tweet = tweet.split()          \n",
    "    return tweet.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq(df.iloc[0].tweet, 'censorship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining word list based on Preotiuc-Pietro et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"../data/combined.txt\", \"r\")\n",
    "words = text_file.read().split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in unique_words:\n",
    "        unique_words.append(w)\n",
    "        \n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "      <th>president</th>\n",
       "      <th>freedom</th>\n",
       "      <th>violence</th>\n",
       "      <th>...</th>\n",
       "      <th>devotion</th>\n",
       "      <th>counteveryvote</th>\n",
       "      <th>voteresponsibly</th>\n",
       "      <th>teamtrump</th>\n",
       "      <th>hunterbidenemails</th>\n",
       "      <th>respectful</th>\n",
       "      <th>presidenttrump</th>\n",
       "      <th>landslide</th>\n",
       "      <th>tie</th>\n",
       "      <th>victory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>trump: as a student i used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>you get a tie! and you get a tie!  trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@clady62 her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>trump  presidenttrump  trump2020landslidevict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06   trump: as a student i used to hear for years,...   \n",
       "1  4.741380e+07  you get a tie! and you get a tie!  trump ‘s ra...   \n",
       "2  1.138416e+09  @clady62 her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  one of the single most effective remedies to e...   \n",
       "4  1.243315e+18   trump  presidenttrump  trump2020landslidevict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  president  \\\n",
       "0                Oregon    2.0            1.0      0.461917     -1          0   \n",
       "1  District of Columbia    4.0            3.0      0.000000      0          0   \n",
       "2            California    2.0            0.0     -0.323204      1          0   \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1          0   \n",
       "4            California    3.0            5.0      0.513350     -1          0   \n",
       "\n",
       "   freedom  violence  ...  devotion  counteveryvote  voteresponsibly  \\\n",
       "0        0         0  ...         0               0                0   \n",
       "1        0         0  ...         0               0                0   \n",
       "2        0         0  ...         0               0                0   \n",
       "3        0         0  ...         0               0                0   \n",
       "4        0         0  ...         0               0                0   \n",
       "\n",
       "   teamtrump  hunterbidenemails  respectful  presidenttrump  landslide  tie  \\\n",
       "0          0                  0           0               0          0    0   \n",
       "1          0                  0           0               0          0    0   \n",
       "2          0                  0           0               0          0    0   \n",
       "3          0                  0           0               0          0    0   \n",
       "4          0                  0           0               1          0    0   \n",
       "\n",
       "   victory  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in unique_words:\n",
    "    df[w] = df['tweet'].apply(lambda x: freq(x, w))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/frequency_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_-1</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Northern Mariana Islands</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>0.327670</td>\n",
       "      <td>0.163835</td>\n",
       "      <td>0.508495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.319932</td>\n",
       "      <td>0.209088</td>\n",
       "      <td>0.470980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.381533</td>\n",
       "      <td>0.150697</td>\n",
       "      <td>0.467770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>0.313824</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.465440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>0.353246</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>0.454263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0.309904</td>\n",
       "      <td>0.239617</td>\n",
       "      <td>0.450479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>0.356086</td>\n",
       "      <td>0.194490</td>\n",
       "      <td>0.449424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>0.346671</td>\n",
       "      <td>0.205254</td>\n",
       "      <td>0.448076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>0.352308</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>0.365325</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.442724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>0.352839</td>\n",
       "      <td>0.204595</td>\n",
       "      <td>0.442566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.337679</td>\n",
       "      <td>0.221706</td>\n",
       "      <td>0.440615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>0.329764</td>\n",
       "      <td>0.233405</td>\n",
       "      <td>0.436831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>0.351816</td>\n",
       "      <td>0.213193</td>\n",
       "      <td>0.434990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>0.379427</td>\n",
       "      <td>0.187184</td>\n",
       "      <td>0.433390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.347080</td>\n",
       "      <td>0.220053</td>\n",
       "      <td>0.432867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>0.359857</td>\n",
       "      <td>0.207838</td>\n",
       "      <td>0.432304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>0.329233</td>\n",
       "      <td>0.239696</td>\n",
       "      <td>0.431072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>0.339196</td>\n",
       "      <td>0.231993</td>\n",
       "      <td>0.428811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>0.373436</td>\n",
       "      <td>0.199230</td>\n",
       "      <td>0.427334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>0.333041</td>\n",
       "      <td>0.243646</td>\n",
       "      <td>0.423313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>0.343387</td>\n",
       "      <td>0.236659</td>\n",
       "      <td>0.419954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>0.360764</td>\n",
       "      <td>0.219579</td>\n",
       "      <td>0.419657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.368825</td>\n",
       "      <td>0.211855</td>\n",
       "      <td>0.419319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>0.366217</td>\n",
       "      <td>0.215756</td>\n",
       "      <td>0.418027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>0.357186</td>\n",
       "      <td>0.226699</td>\n",
       "      <td>0.416115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>0.358396</td>\n",
       "      <td>0.226280</td>\n",
       "      <td>0.415324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.238721</td>\n",
       "      <td>0.414620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.347327</td>\n",
       "      <td>0.244881</td>\n",
       "      <td>0.407792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>0.304438</td>\n",
       "      <td>0.289182</td>\n",
       "      <td>0.406380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>0.413127</td>\n",
       "      <td>0.181467</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>0.346633</td>\n",
       "      <td>0.249377</td>\n",
       "      <td>0.403990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>0.341365</td>\n",
       "      <td>0.255020</td>\n",
       "      <td>0.403614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>0.353309</td>\n",
       "      <td>0.243888</td>\n",
       "      <td>0.402803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>0.362683</td>\n",
       "      <td>0.235164</td>\n",
       "      <td>0.402153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>0.330377</td>\n",
       "      <td>0.270510</td>\n",
       "      <td>0.399113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>0.367925</td>\n",
       "      <td>0.233753</td>\n",
       "      <td>0.398323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>0.343066</td>\n",
       "      <td>0.259124</td>\n",
       "      <td>0.397810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>0.407708</td>\n",
       "      <td>0.194726</td>\n",
       "      <td>0.397566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>0.341772</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.397468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>0.324071</td>\n",
       "      <td>0.278821</td>\n",
       "      <td>0.397109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>0.352101</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.395798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>0.336565</td>\n",
       "      <td>0.274743</td>\n",
       "      <td>0.388692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>0.338816</td>\n",
       "      <td>0.273026</td>\n",
       "      <td>0.388158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.292914</td>\n",
       "      <td>0.323228</td>\n",
       "      <td>0.383858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.254079</td>\n",
       "      <td>0.382284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>0.331046</td>\n",
       "      <td>0.309605</td>\n",
       "      <td>0.359348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>0.327842</td>\n",
       "      <td>0.313015</td>\n",
       "      <td>0.359143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>0.366430</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.356974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.322017</td>\n",
       "      <td>0.380213</td>\n",
       "      <td>0.297769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          label_-1   label_0   label_1\n",
       "state                                                 \n",
       "Northern Mariana Islands  0.000000  0.000000  1.000000\n",
       "Vermont                   0.327670  0.163835  0.508495\n",
       "Pennsylvania              0.319932  0.209088  0.470980\n",
       "Oregon                    0.381533  0.150697  0.467770\n",
       "Wisconsin                 0.313824  0.220736  0.465440\n",
       "Massachusetts             0.353246  0.192491  0.454263\n",
       "Delaware                  0.309904  0.239617  0.450479\n",
       "Virginia                  0.356086  0.194490  0.449424\n",
       "Illinois                  0.346671  0.205254  0.448076\n",
       "South Carolina            0.352308  0.200000  0.447692\n",
       "South Dakota              0.329412  0.223529  0.447059\n",
       "Montana                   0.365325  0.191950  0.442724\n",
       "Maryland                  0.352839  0.204595  0.442566\n",
       "New York                  0.337679  0.221706  0.440615\n",
       "North Dakota              0.329764  0.233405  0.436831\n",
       "Kansas                    0.351816  0.213193  0.434990\n",
       "Idaho                     0.379427  0.187184  0.433390\n",
       "California                0.347080  0.220053  0.432867\n",
       "Iowa                      0.359857  0.207838  0.432304\n",
       "District of Columbia      0.329233  0.239696  0.431072\n",
       "Louisiana                 0.339196  0.231993  0.428811\n",
       "Minnesota                 0.373436  0.199230  0.427334\n",
       "Missouri                  0.333041  0.243646  0.423313\n",
       "Oklahoma                  0.343387  0.236659  0.419954\n",
       "Tennessee                 0.360764  0.219579  0.419657\n",
       "Washington                0.368825  0.211855  0.419319\n",
       "Kentucky                  0.366217  0.215756  0.418027\n",
       "Michigan                  0.357186  0.226699  0.416115\n",
       "Georgia                   0.358396  0.226280  0.415324\n",
       "North Carolina            0.346659  0.238721  0.414620\n",
       "Texas                     0.347327  0.244881  0.407792\n",
       "Indiana                   0.304438  0.289182  0.406380\n",
       "Mississippi               0.413127  0.181467  0.405405\n",
       "New Hampshire             0.346633  0.249377  0.403990\n",
       "New Mexico                0.341365  0.255020  0.403614\n",
       "Colorado                  0.353309  0.243888  0.402803\n",
       "Arizona                   0.362683  0.235164  0.402153\n",
       "Maine                     0.330377  0.270510  0.399113\n",
       "Alabama                   0.367925  0.233753  0.398323\n",
       "Wyoming                   0.343066  0.259124  0.397810\n",
       "Alaska                    0.407708  0.194726  0.397566\n",
       "West Virginia             0.341772  0.260759  0.397468\n",
       "New Jersey                0.324071  0.278821  0.397109\n",
       "Nevada                    0.352101  0.252101  0.395798\n",
       "Florida                   0.336565  0.274743  0.388692\n",
       "Rhode Island              0.338816  0.273026  0.388158\n",
       "Ohio                      0.292914  0.323228  0.383858\n",
       "Hawaii                    0.363636  0.254079  0.382284\n",
       "Connecticut               0.331046  0.309605  0.359348\n",
       "Arkansas                  0.327842  0.313015  0.359143\n",
       "Nebraska                  0.366430  0.276596  0.356974\n",
       "Utah                      0.322017  0.380213  0.297769"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.get_dummies(df, columns=['label'])\n",
    "state_perc = df2[['state','label_-1','label_0','label_1']].groupby('state').mean()\n",
    "state_perc.sort_values('label_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['tweet','avg_polarity', 'label'], axis=1)\n",
    "y = df[['state', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['state'].isin(\n",
    "    ['Vermont', 'Oregon', 'Massachusetts', \n",
    "     'Delaware', 'Virginia', 'Mississippi',\n",
    "     'Alaska', 'Idaho', 'Alabama'\n",
    "    ])].drop('state', axis=1)\n",
    "y_train = y[y['state'].isin(\n",
    "    ['Vermont', 'Oregon', 'Massachusetts', \n",
    "     'Delaware', 'Virginia', 'Mississippi',\n",
    "     'Alaska', 'Idaho', 'Alabama'\n",
    "    ])]['label']\n",
    "\n",
    "X_test = X[X['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])].drop('state', axis=1)\n",
    "y_test = y[y['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 153 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57121630227128"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='saga', max_iter=1000, \n",
    "                        C=0.9, dual=False,\n",
    "                        penalty='elasticnet', l1_ratio=0.25, \n",
    "                        random_state=42, n_jobs=-1, verbose=True)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5395600787918582"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9980           0.0213           13.72s\n",
      "         2           0.9768           0.0165           11.93s\n",
      "         3           0.9553           0.0143           11.08s\n",
      "         4           0.9436           0.0109           10.96s\n",
      "         5           0.9228           0.0109           10.52s\n",
      "         6           0.9097           0.0094           10.46s\n",
      "         7           0.8982           0.0077           10.22s\n",
      "         8           0.8845           0.0064            9.91s\n",
      "         9           0.8714           0.0056            9.63s\n",
      "        10           0.8621           0.0040            9.47s\n",
      "        11           0.8503           0.0043            9.24s\n",
      "        12           0.8476           0.0032            8.88s\n",
      "        13           0.8394           0.0035            8.48s\n",
      "        14           0.8380           0.0031            8.20s\n",
      "        15           0.8294           0.0033            8.10s\n",
      "        16           0.8151           0.0023            8.02s\n",
      "        17           0.8176           0.0018            7.60s\n",
      "        18           0.8120           0.0027            7.26s\n",
      "        19           0.7987           0.0028            7.02s\n",
      "        20           0.8041           0.0018            6.67s\n",
      "        21           0.7955           0.0017            6.29s\n",
      "        22           0.7924           0.0010            5.93s\n",
      "        23           0.7910           0.0016            5.63s\n",
      "        24           0.7927           0.0014            5.36s\n",
      "        25           0.7850           0.0002            5.06s\n",
      "        26           0.7732           0.0013            4.70s\n",
      "        27           0.7665           0.0012            4.35s\n",
      "        28           0.7627           0.0005            4.01s\n",
      "        29           0.7641           0.0008            3.67s\n",
      "        30           0.7600           0.0010            3.33s\n",
      "        31           0.7585           0.0011            2.99s\n",
      "        32           0.7551           0.0004            2.65s\n",
      "        33           0.7544           0.0004            2.31s\n",
      "        34           0.7502           0.0008            1.98s\n",
      "        35           0.7404           0.0000            1.65s\n",
      "        36           0.7381           0.0003            1.32s\n",
      "        37           0.7418           0.0008            0.99s\n",
      "        38           0.7396           0.0002            0.66s\n",
      "        39           0.7348           0.0000            0.33s\n",
      "        40           0.7339           0.0001            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6888134154107408"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbk = GradientBoostingClassifier(loss='deviance', n_estimators=40, \n",
    "                                 subsample=0.4, n_iter_no_change=5,\n",
    "                                 max_depth=10, random_state=42, verbose=2)\n",
    "gbk.fit(X_train, y_train)\n",
    "\n",
    "gbk.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5455515430072226"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbk.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5368286987900658"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion='gini', splitter='best',\n",
    "                                 max_depth=9, random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "dtree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5127216021011162"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree + AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579919337720229"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(dtree, n_estimators=500, \n",
    "                              random_state=42)\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "adaboost.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4997537754432042"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6612184249628529"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=1000,\n",
    "                                max_depth=15, random_state=42, \n",
    "                                n_jobs=-1, verbose=True)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5277413000656599"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.00773266\n",
      "Iteration 2, loss = 0.88991535\n",
      "Iteration 3, loss = 0.84940562\n",
      "Iteration 4, loss = 0.83732642\n",
      "Iteration 5, loss = 0.83244409\n",
      "Iteration 6, loss = 0.82983282\n",
      "Iteration 7, loss = 0.82641395\n",
      "Iteration 8, loss = 0.82320534\n",
      "Iteration 9, loss = 0.82102374\n",
      "Iteration 10, loss = 0.81983503\n",
      "Iteration 11, loss = 0.81944940\n",
      "Iteration 12, loss = 0.81579135\n",
      "Iteration 13, loss = 0.81264557\n",
      "Iteration 14, loss = 0.81024200\n",
      "Iteration 15, loss = 0.80766739\n",
      "Iteration 16, loss = 0.80749376\n",
      "Iteration 17, loss = 0.80399346\n",
      "Iteration 18, loss = 0.79820341\n",
      "Iteration 19, loss = 0.79573314\n",
      "Iteration 20, loss = 0.79176668\n",
      "Iteration 21, loss = 0.78565187\n",
      "Iteration 22, loss = 0.78114316\n",
      "Iteration 23, loss = 0.77418730\n",
      "Iteration 24, loss = 0.76626096\n",
      "Iteration 25, loss = 0.75849531\n",
      "Iteration 26, loss = 0.75115833\n",
      "Iteration 27, loss = 0.73964500\n",
      "Iteration 28, loss = 0.73105115\n",
      "Iteration 29, loss = 0.72303590\n",
      "Iteration 30, loss = 0.71153086\n",
      "Iteration 31, loss = 0.69803011\n",
      "Iteration 32, loss = 0.68755471\n",
      "Iteration 33, loss = 0.67487449\n",
      "Iteration 34, loss = 0.66398585\n",
      "Iteration 35, loss = 0.65483088\n",
      "Iteration 36, loss = 0.64519819\n",
      "Iteration 37, loss = 0.63318246\n",
      "Iteration 38, loss = 0.62650207\n",
      "Iteration 39, loss = 0.61921143\n",
      "Iteration 40, loss = 0.60854743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7329654001273614"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), activation='logistic', \n",
    "                    random_state=42, max_iter=40, \n",
    "                    solver='adam', verbose=True)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5392317793827971"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined, Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7439326399207529"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(estimators=[('Logistic', lr), \n",
    "                                      ('Gradient Boosting', gbk), \n",
    "                                      ('DTree', dtree), \n",
    "                                      ('AdaBoost', adaboost), \n",
    "                                      ('Random Forest', forest),\n",
    "                                      ('Neural NetWork', mlp)],\n",
    "                          voting='soft', n_jobs=-1, verbose=True)\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "voting.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5567137229152987"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.5395600787918582\n",
      "Gradient Boosting:  0.5455515430072226\n",
      "Decision Tree:  0.5127216021011162\n",
      "AdaBoost:  0.4997537754432042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  0.5277413000656599\n",
      "Neural Network:  0.5392317793827971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting:  0.5567137229152987\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression: ', lr.score(X_test, y_test))\n",
    "print('Gradient Boosting: ', gbk.score(X_test, y_test))\n",
    "print('Decision Tree: ', dtree.score(X_test, y_test))\n",
    "print('AdaBoost: ', adaboost.score(X_test, y_test))\n",
    "print('Random Forest: ', forest.score(X_test, y_test))\n",
    "print('Neural Network: ', mlp.score(X_test, y_test))\n",
    "print('Voting: ', voting.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Final Vote Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "y_hat = voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df[['state', 'label']]\n",
    "y_df = y_df[y_df['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])]\n",
    "y_df['Prdiction'] = y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Matching for each label (better than overall accuracy?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matched</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.511202</td>\n",
       "      <td>0.183670</td>\n",
       "      <td>0.305129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.184284</td>\n",
       "      <td>0.241044</td>\n",
       "      <td>0.574672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               -1         0         1\n",
       "Matched                              \n",
       "False    0.511202  0.183670  0.305129\n",
       "True     0.184284  0.241044  0.574672"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df['Matched'] = y_df['Prdiction'] == y_df['label']\n",
    "\n",
    "y_df2 = pd.get_dummies(y_df['label'])\n",
    "y_df2['Matched'] = y_df['Matched']\n",
    "\n",
    "y_df2.groupby('Matched').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df3 = pd.get_dummies(y_df['Prdiction'])\n",
    "y_df3['state'] = y_df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Michigan        5.321708\n",
       "Pennsylvania    9.668743\n",
       "Wisconsin       6.410256\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_df3.groupby('state').mean()[1] - 0.5) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
