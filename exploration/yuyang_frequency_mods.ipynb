{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/combined_labeled_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>One of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>#Trump #PresidentTrump #Trump2020LandslideVict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06  #Trump: As a student I used to hear for years,...   \n",
       "1  4.741380e+07  You get a tie! And you get a tie! #Trump ‘s ra...   \n",
       "2  1.138416e+09  @CLady62 Her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  One of the single most effective remedies to e...   \n",
       "4  1.243315e+18  #Trump #PresidentTrump #Trump2020LandslideVict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  \n",
       "0                Oregon    2.0            1.0      0.461917     -1  \n",
       "1  District of Columbia    4.0            3.0      0.000000      0  \n",
       "2            California    2.0            0.0     -0.323204      1  \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1  \n",
       "4            California    3.0            5.0      0.513350     -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>#trump: as a student i used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>you get a tie! and you get a tie! #trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@clady62 her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>#trump #presidenttrump #trump2020landslidevict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06  #trump: as a student i used to hear for years,...   \n",
       "1  4.741380e+07  you get a tie! and you get a tie! #trump ‘s ra...   \n",
       "2  1.138416e+09  @clady62 her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  one of the single most effective remedies to e...   \n",
       "4  1.243315e+18  #trump #presidenttrump #trump2020landslidevict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  \n",
       "0                Oregon    2.0            1.0      0.461917     -1  \n",
       "1  District of Columbia    4.0            3.0      0.000000      0  \n",
       "2            California    2.0            0.0     -0.323204      1  \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1  \n",
       "4            California    3.0            5.0      0.513350     -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: str(x).lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>trump: as a student i used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>you get a tie! and you get a tie!  trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@clady62 her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>trump  presidenttrump  trump2020landslidevict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06   trump: as a student i used to hear for years,...   \n",
       "1  4.741380e+07  you get a tie! and you get a tie!  trump ‘s ra...   \n",
       "2  1.138416e+09  @clady62 her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  one of the single most effective remedies to e...   \n",
       "4  1.243315e+18   trump  presidenttrump  trump2020landslidevict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  \n",
       "0                Oregon    2.0            1.0      0.461917     -1  \n",
       "1  District of Columbia    4.0            3.0      0.000000      0  \n",
       "2            California    2.0            0.0     -0.323204      1  \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1  \n",
       "4            California    3.0            5.0      0.513350     -1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('#', ' ', x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(tweet, word): \n",
    "    tweet = tweet.split()          \n",
    "    return tweet.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq(df.iloc[0].tweet, 'censorship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining word list based on Preotiuc-Pietro et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"../data/combined.txt\", \"r\")\n",
    "words = text_file.read().split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in unique_words:\n",
    "        unique_words.append(w)\n",
    "        \n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>state</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>label</th>\n",
       "      <th>president</th>\n",
       "      <th>freedom</th>\n",
       "      <th>violence</th>\n",
       "      <th>...</th>\n",
       "      <th>devotion</th>\n",
       "      <th>counteveryvote</th>\n",
       "      <th>voteresponsibly</th>\n",
       "      <th>teamtrump</th>\n",
       "      <th>hunterbidenemails</th>\n",
       "      <th>respectful</th>\n",
       "      <th>presidenttrump</th>\n",
       "      <th>landslide</th>\n",
       "      <th>tie</th>\n",
       "      <th>victory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>trump: as a student i used to hear for years,...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461917</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>you get a tie! and you get a tie!  trump ‘s ra...</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>@clady62 her 15 minutes were over long time ag...</td>\n",
       "      <td>California</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404769e+08</td>\n",
       "      <td>one of the single most effective remedies to e...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366371</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243315e+18</td>\n",
       "      <td>trump  presidenttrump  trump2020landslidevict...</td>\n",
       "      <td>California</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.513350</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                              tweet  \\\n",
       "0  8.436472e+06   trump: as a student i used to hear for years,...   \n",
       "1  4.741380e+07  you get a tie! and you get a tie!  trump ‘s ra...   \n",
       "2  1.138416e+09  @clady62 her 15 minutes were over long time ag...   \n",
       "3  5.404769e+08  one of the single most effective remedies to e...   \n",
       "4  1.243315e+18   trump  presidenttrump  trump2020landslidevict...   \n",
       "\n",
       "                  state  likes  retweet_count  avg_polarity  label  president  \\\n",
       "0                Oregon    2.0            1.0      0.461917     -1          0   \n",
       "1  District of Columbia    4.0            3.0      0.000000      0          0   \n",
       "2            California    2.0            0.0     -0.323204      1          0   \n",
       "3          Pennsylvania    0.0            0.0      0.366371     -1          0   \n",
       "4            California    3.0            5.0      0.513350     -1          0   \n",
       "\n",
       "   freedom  violence  ...  devotion  counteveryvote  voteresponsibly  \\\n",
       "0        0         0  ...         0               0                0   \n",
       "1        0         0  ...         0               0                0   \n",
       "2        0         0  ...         0               0                0   \n",
       "3        0         0  ...         0               0                0   \n",
       "4        0         0  ...         0               0                0   \n",
       "\n",
       "   teamtrump  hunterbidenemails  respectful  presidenttrump  landslide  tie  \\\n",
       "0          0                  0           0               0          0    0   \n",
       "1          0                  0           0               0          0    0   \n",
       "2          0                  0           0               0          0    0   \n",
       "3          0                  0           0               0          0    0   \n",
       "4          0                  0           0               1          0    0   \n",
       "\n",
       "   victory  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in unique_words:\n",
    "    df[w] = df['tweet'].apply(lambda x: freq(x, w))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/frequency_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/frequency_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_-1</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Northern Mariana Islands</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>0.327670</td>\n",
       "      <td>0.163835</td>\n",
       "      <td>0.508495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.319932</td>\n",
       "      <td>0.209088</td>\n",
       "      <td>0.470980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.381533</td>\n",
       "      <td>0.150697</td>\n",
       "      <td>0.467770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>0.313824</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.465440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>0.353246</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>0.454263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0.309904</td>\n",
       "      <td>0.239617</td>\n",
       "      <td>0.450479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>0.356086</td>\n",
       "      <td>0.194490</td>\n",
       "      <td>0.449424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>0.346671</td>\n",
       "      <td>0.205254</td>\n",
       "      <td>0.448076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>0.352308</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>0.365325</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.442724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>0.352839</td>\n",
       "      <td>0.204595</td>\n",
       "      <td>0.442566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.337679</td>\n",
       "      <td>0.221706</td>\n",
       "      <td>0.440615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>0.329764</td>\n",
       "      <td>0.233405</td>\n",
       "      <td>0.436831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>0.351816</td>\n",
       "      <td>0.213193</td>\n",
       "      <td>0.434990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>0.379427</td>\n",
       "      <td>0.187184</td>\n",
       "      <td>0.433390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.347080</td>\n",
       "      <td>0.220053</td>\n",
       "      <td>0.432867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>0.359857</td>\n",
       "      <td>0.207838</td>\n",
       "      <td>0.432304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>0.329233</td>\n",
       "      <td>0.239696</td>\n",
       "      <td>0.431072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>0.339196</td>\n",
       "      <td>0.231993</td>\n",
       "      <td>0.428811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>0.373436</td>\n",
       "      <td>0.199230</td>\n",
       "      <td>0.427334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>0.333041</td>\n",
       "      <td>0.243646</td>\n",
       "      <td>0.423313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>0.343387</td>\n",
       "      <td>0.236659</td>\n",
       "      <td>0.419954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>0.360764</td>\n",
       "      <td>0.219579</td>\n",
       "      <td>0.419657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.368825</td>\n",
       "      <td>0.211855</td>\n",
       "      <td>0.419319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>0.366217</td>\n",
       "      <td>0.215756</td>\n",
       "      <td>0.418027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>0.357186</td>\n",
       "      <td>0.226699</td>\n",
       "      <td>0.416115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>0.358396</td>\n",
       "      <td>0.226280</td>\n",
       "      <td>0.415324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>0.346659</td>\n",
       "      <td>0.238721</td>\n",
       "      <td>0.414620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.347327</td>\n",
       "      <td>0.244881</td>\n",
       "      <td>0.407792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>0.304438</td>\n",
       "      <td>0.289182</td>\n",
       "      <td>0.406380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>0.413127</td>\n",
       "      <td>0.181467</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>0.346633</td>\n",
       "      <td>0.249377</td>\n",
       "      <td>0.403990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>0.341365</td>\n",
       "      <td>0.255020</td>\n",
       "      <td>0.403614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>0.353309</td>\n",
       "      <td>0.243888</td>\n",
       "      <td>0.402803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>0.362683</td>\n",
       "      <td>0.235164</td>\n",
       "      <td>0.402153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>0.330377</td>\n",
       "      <td>0.270510</td>\n",
       "      <td>0.399113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>0.367925</td>\n",
       "      <td>0.233753</td>\n",
       "      <td>0.398323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>0.343066</td>\n",
       "      <td>0.259124</td>\n",
       "      <td>0.397810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>0.407708</td>\n",
       "      <td>0.194726</td>\n",
       "      <td>0.397566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>0.341772</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.397468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>0.324071</td>\n",
       "      <td>0.278821</td>\n",
       "      <td>0.397109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>0.352101</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.395798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>0.336565</td>\n",
       "      <td>0.274743</td>\n",
       "      <td>0.388692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>0.338816</td>\n",
       "      <td>0.273026</td>\n",
       "      <td>0.388158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.292914</td>\n",
       "      <td>0.323228</td>\n",
       "      <td>0.383858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.254079</td>\n",
       "      <td>0.382284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>0.331046</td>\n",
       "      <td>0.309605</td>\n",
       "      <td>0.359348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>0.327842</td>\n",
       "      <td>0.313015</td>\n",
       "      <td>0.359143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>0.366430</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.356974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.322017</td>\n",
       "      <td>0.380213</td>\n",
       "      <td>0.297769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          label_-1   label_0   label_1\n",
       "state                                                 \n",
       "Northern Mariana Islands  0.000000  0.000000  1.000000\n",
       "Vermont                   0.327670  0.163835  0.508495\n",
       "Pennsylvania              0.319932  0.209088  0.470980\n",
       "Oregon                    0.381533  0.150697  0.467770\n",
       "Wisconsin                 0.313824  0.220736  0.465440\n",
       "Massachusetts             0.353246  0.192491  0.454263\n",
       "Delaware                  0.309904  0.239617  0.450479\n",
       "Virginia                  0.356086  0.194490  0.449424\n",
       "Illinois                  0.346671  0.205254  0.448076\n",
       "South Carolina            0.352308  0.200000  0.447692\n",
       "South Dakota              0.329412  0.223529  0.447059\n",
       "Montana                   0.365325  0.191950  0.442724\n",
       "Maryland                  0.352839  0.204595  0.442566\n",
       "New York                  0.337679  0.221706  0.440615\n",
       "North Dakota              0.329764  0.233405  0.436831\n",
       "Kansas                    0.351816  0.213193  0.434990\n",
       "Idaho                     0.379427  0.187184  0.433390\n",
       "California                0.347080  0.220053  0.432867\n",
       "Iowa                      0.359857  0.207838  0.432304\n",
       "District of Columbia      0.329233  0.239696  0.431072\n",
       "Louisiana                 0.339196  0.231993  0.428811\n",
       "Minnesota                 0.373436  0.199230  0.427334\n",
       "Missouri                  0.333041  0.243646  0.423313\n",
       "Oklahoma                  0.343387  0.236659  0.419954\n",
       "Tennessee                 0.360764  0.219579  0.419657\n",
       "Washington                0.368825  0.211855  0.419319\n",
       "Kentucky                  0.366217  0.215756  0.418027\n",
       "Michigan                  0.357186  0.226699  0.416115\n",
       "Georgia                   0.358396  0.226280  0.415324\n",
       "North Carolina            0.346659  0.238721  0.414620\n",
       "Texas                     0.347327  0.244881  0.407792\n",
       "Indiana                   0.304438  0.289182  0.406380\n",
       "Mississippi               0.413127  0.181467  0.405405\n",
       "New Hampshire             0.346633  0.249377  0.403990\n",
       "New Mexico                0.341365  0.255020  0.403614\n",
       "Colorado                  0.353309  0.243888  0.402803\n",
       "Arizona                   0.362683  0.235164  0.402153\n",
       "Maine                     0.330377  0.270510  0.399113\n",
       "Alabama                   0.367925  0.233753  0.398323\n",
       "Wyoming                   0.343066  0.259124  0.397810\n",
       "Alaska                    0.407708  0.194726  0.397566\n",
       "West Virginia             0.341772  0.260759  0.397468\n",
       "New Jersey                0.324071  0.278821  0.397109\n",
       "Nevada                    0.352101  0.252101  0.395798\n",
       "Florida                   0.336565  0.274743  0.388692\n",
       "Rhode Island              0.338816  0.273026  0.388158\n",
       "Ohio                      0.292914  0.323228  0.383858\n",
       "Hawaii                    0.363636  0.254079  0.382284\n",
       "Connecticut               0.331046  0.309605  0.359348\n",
       "Arkansas                  0.327842  0.313015  0.359143\n",
       "Nebraska                  0.366430  0.276596  0.356974\n",
       "Utah                      0.322017  0.380213  0.297769"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.get_dummies(df, columns=['label'])\n",
    "state_perc = df2[['state','label_-1','label_0','label_1']].groupby('state').mean()\n",
    "state_perc.sort_values('label_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['tweet','avg_polarity', 'label'], axis=1)\n",
    "y = df[['state', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X[X['state'].isin(\n",
    "#     ['Vermont', 'Oregon', 'Massachusetts', \n",
    "#      'Delaware', 'Virginia', 'Mississippi',\n",
    "#      'Alaska', 'Idaho', 'Alabama'\n",
    "#     ])].drop('state', axis=1)\n",
    "# y_train = y[y['state'].isin(\n",
    "#     ['Vermont', 'Oregon', 'Massachusetts', \n",
    "#      'Delaware', 'Virginia', 'Mississippi',\n",
    "#      'Alaska', 'Idaho', 'Alabama'\n",
    "#     ])]['label']\n",
    "\n",
    "X_train = X[~X['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])].drop('state', axis=1)\n",
    "y_train = y[~y['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])]['label']\n",
    "\n",
    "X_test = X[X['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])].drop('state', axis=1)\n",
    "y_test = y[y['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 182 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5652921471556043"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='saga', max_iter=100, \n",
    "                        C=0.9, dual=False,\n",
    "                        penalty='elasticnet', l1_ratio=0.25, \n",
    "                        random_state=42, n_jobs=-1, verbose=True)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5588476690741957"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0401           0.0290            4.93m\n",
      "         2           1.0151           0.0245            4.97m\n",
      "         3           0.9943           0.0202            4.76m\n",
      "         4           0.9754           0.0165            4.68m\n",
      "         5           0.9608           0.0143            4.50m\n",
      "         6           0.9480           0.0123            4.41m\n",
      "         7           0.9353           0.0108            4.26m\n",
      "         8           0.9256           0.0090            4.16m\n",
      "         9           0.9156           0.0081            4.00m\n",
      "        10           0.9069           0.0071            3.88m\n",
      "        11           0.9008           0.0063            3.75m\n",
      "        12           0.8944           0.0057            3.63m\n",
      "        13           0.8879           0.0052            3.51m\n",
      "        14           0.8804           0.0046            3.37m\n",
      "        15           0.8775           0.0046            3.26m\n",
      "        16           0.8722           0.0039            3.12m\n",
      "        17           0.8660           0.0038            3.01m\n",
      "        18           0.8639           0.0033            2.88m\n",
      "        19           0.8593           0.0033            2.76m\n",
      "        20           0.8538           0.0033            2.64m\n",
      "        21           0.8523           0.0027            2.51m\n",
      "        22           0.8450           0.0024            2.39m\n",
      "        23           0.8433           0.0030            2.25m\n",
      "        24           0.8406           0.0026            2.13m\n",
      "        25           0.8375           0.0023            2.00m\n",
      "        26           0.8327           0.0025            1.87m\n",
      "        27           0.8308           0.0019            1.75m\n",
      "        28           0.8278           0.0022            1.61m\n",
      "        29           0.8246           0.0023            1.48m\n",
      "        30           0.8211           0.0017            1.35m\n",
      "        31           0.8210           0.0016            1.22m\n",
      "        32           0.8182           0.0017            1.09m\n",
      "        33           0.8167           0.0018           57.36s\n",
      "        34           0.8116           0.0020           49.29s\n",
      "        35           0.8113           0.0014           41.18s\n",
      "        36           0.8091           0.0014           33.01s\n",
      "        37           0.8068           0.0012           24.86s\n",
      "        38           0.8053           0.0012           16.61s\n",
      "        39           0.8038           0.0010            8.32s\n",
      "        40           0.8035           0.0012            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6368422612871669"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbk = GradientBoostingClassifier(loss='deviance', n_estimators=40, \n",
    "                                 subsample=0.4, n_iter_no_change=5,\n",
    "                                 max_depth=10, random_state=42, verbose=2)\n",
    "gbk.fit(X_train, y_train)\n",
    "\n",
    "gbk.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5867531188443861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbk.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5334123854978804"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion='gini', splitter='best',\n",
    "                                 max_depth=9, random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "dtree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5168253447143795"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree + AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.806492159013429"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(dtree, n_estimators=250, \n",
    "                              random_state=42)\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "adaboost.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5044320420223244"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5932054664571784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=100,\n",
    "                                max_depth=15, random_state=42, \n",
    "                                n_jobs=-1, verbose=True)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.564510833880499"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.89549410\n",
      "Iteration 2, loss = 0.85549962\n",
      "Iteration 3, loss = 0.84911710\n",
      "Iteration 4, loss = 0.83976989\n",
      "Iteration 5, loss = 0.81633766\n",
      "Iteration 6, loss = 0.79730943\n",
      "Iteration 7, loss = 0.78725092\n",
      "Iteration 8, loss = 0.78174151\n",
      "Iteration 9, loss = 0.77658372\n",
      "Iteration 10, loss = 0.77326633\n",
      "Iteration 11, loss = 0.77061209\n",
      "Iteration 12, loss = 0.76820301\n",
      "Iteration 13, loss = 0.76611689\n",
      "Iteration 14, loss = 0.76403443\n",
      "Iteration 15, loss = 0.76268177\n",
      "Iteration 16, loss = 0.76081461\n",
      "Iteration 17, loss = 0.75949045\n",
      "Iteration 18, loss = 0.75830834\n",
      "Iteration 19, loss = 0.75688003\n",
      "Iteration 20, loss = 0.75535302\n",
      "Iteration 21, loss = 0.75474411\n",
      "Iteration 22, loss = 0.75334764\n",
      "Iteration 23, loss = 0.75262311\n",
      "Iteration 24, loss = 0.75140893\n",
      "Iteration 25, loss = 0.75073052\n",
      "Iteration 26, loss = 0.74991037\n",
      "Iteration 27, loss = 0.74908884\n",
      "Iteration 28, loss = 0.74808340\n",
      "Iteration 29, loss = 0.74735503\n",
      "Iteration 30, loss = 0.74681729\n",
      "Iteration 31, loss = 0.74605187\n",
      "Iteration 32, loss = 0.74553467\n",
      "Iteration 33, loss = 0.74472435\n",
      "Iteration 34, loss = 0.74418569\n",
      "Iteration 35, loss = 0.74344733\n",
      "Iteration 36, loss = 0.74289561\n",
      "Iteration 37, loss = 0.74233226\n",
      "Iteration 38, loss = 0.74190832\n",
      "Iteration 39, loss = 0.74116967\n",
      "Iteration 40, loss = 0.74064360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.653692230160377"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(25, 100), activation='logistic', \n",
    "                    random_state=42, max_iter=40, \n",
    "                    solver='adam', verbose=True)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972586999343401"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined, Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6541784009723416"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(estimators=[('Logistic', lr), \n",
    "                                      ('Gradient Boosting', gbk), \n",
    "                                      ('DTree', dtree), \n",
    "                                      ('AdaBoost', adaboost), \n",
    "                                      ('Random Forest', forest),\n",
    "                                      ('Neural NetWork', mlp)],\n",
    "                          voting='soft', n_jobs=-1, verbose=True)\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "voting.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5881483913328956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.5588476690741957\n",
      "Gradient Boosting:  0.5867531188443861\n",
      "Decision Tree:  0.5168253447143795\n",
      "AdaBoost:  0.5044320420223244\n",
      "Random Forest:  0.564510833880499\n",
      "Neural Network:  0.5972586999343401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting:  0.5881483913328956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression: ', lr.score(X_test, y_test))\n",
    "print('Gradient Boosting: ', gbk.score(X_test, y_test))\n",
    "print('Decision Tree: ', dtree.score(X_test, y_test))\n",
    "print('AdaBoost: ', adaboost.score(X_test, y_test))\n",
    "print('Random Forest: ', forest.score(X_test, y_test))\n",
    "print('Neural Network: ', mlp.score(X_test, y_test))\n",
    "print('Voting: ', voting.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Final Vote Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df[['state', 'label']]\n",
    "y_df = y_df[y_df['state'].isin(['Michigan', 'Wisconsin', 'Pennsylvania'])]\n",
    "y_df['Prdiction'] = y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Matching for each label (better than overall accuracy?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1    0.418599\n",
       " 0    0.687096\n",
       " 1    0.683916\n",
       "Name: Matched, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df['Matched'] = y_df['Prdiction'] == y_df['label']\n",
    "\n",
    "y_df.groupby('label').mean()['Matched']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df1 = pd.get_dummies(y_df['Prdiction'])\n",
    "y_df1['state'] = y_df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Michigan        6.343957\n",
       "Pennsylvania    6.342016\n",
       "Wisconsin       8.751394\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_df1.groupby('state').mean()[1] - 0.5) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
